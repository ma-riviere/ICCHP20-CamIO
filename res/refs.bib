@InProceedings{guezou-philippePrototypingEvaluatingSensory2018,
  title = {Prototyping and {{Evaluating Sensory Substitution Devices}} by {{Spatial Immersion}} in {{Virtual Environments}}:},
  shorttitle = {Prototyping and {{Evaluating Sensory Substitution Devices}} by {{Spatial Immersion}} in {{Virtual Environments}}},
  booktitle = {Proceedings of the 13th {{International Joint Conference}} on {{Computer Vision}}, {{Imaging}} and {{Computer Graphics Theory}} and {{Applications}}},
  author = {Aziliz Guezou-Philippe and Sylvain Huet and Denis Pellerin and Christian Graff},
  year = {2018},
  pages = {596--602},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {{Funchal, Madeira, Portugal}},
  doi = {10.5220/0006637705960602},
  abstract = {Sensory Substitution, Virtual Environments, Motion Capture, Pointing Device, Eye Tracking.},
  isbn = {978-989-758-290-5},
  language = {en},
}
@InProceedings{mayAuditoryDisplaysFacilitate2019,
  title = {Auditory {{Displays}} to {{Facilitate Object Targeting}} in {{3D Space}}},
  booktitle = {Proceedings of the 25th {{International Conference}} on {{Auditory Display}} ({{ICAD}} 2019)},
  author = {Keenan R. May and Briana Sobel and Jeff Wilson and Bruce N. Walker},
  year = {2019},
  month = {jun},
  pages = {155--162},
  publisher = {{Department of Computer and Information Sciences, Northumbria University}},
  address = {{Newcastle upon Tyne}},
  doi = {10.21785/icad2019.008},
  abstract = {In both extreme and everyday situations, humans need to find nearby objects that cannot be located visually. In such situations, auditory display technology could be used to display information supporting object targeting. Unfortunately, spatial audio inadequately conveys sound source elevation, which is crucial for locating objects in 3D space. To address this, three auditory display concepts were developed and evaluated in the context of finding objects within a virtual room, in either low or no visibility conditions: (1) a one-time height-denoting ``area cue,'' (2) ongoing ``proximity feedback,'' or (3) both. All three led to improvements in performance and subjective workload compared to no sound. Displays (2) and (3) led to the largest improvements. This pattern was smaller, but still present, when visibility was low, compared to no visibility. These results indicate that persons who need to locate nearby objects in limited visibility conditions could benefit from the types of auditory displays considered here.},
  isbn = {978-0-9670904-6-7},
  language = {en},
}
@article{brooke1996sus,
  title={SUS-A quick and dirty usability scale},
  author={Brooke, John and others},
  journal={Usability evaluation in industry},
  volume={189},
  number={194},
  pages={4--7},
  year={1996},
  publisher={London--}
}
@article {coughlanTowardsAccessibleAudioLabeling2020,
	title = {Towards Accessible Audio Labeling of 3D Objects},
	journal = {Journal on Technology and Persons with Disabilities},
	volume = {8},
	year = {2020},
	month = {04/2020},
	type = {In Press},
	abstract = {We describe a new approach to audio labeling of 3D objects such as appliances, 3D models and maps that enables a visually impaired person to audio label objects. Our approach to audio labeling is called CamIO, a smartphone app that issues audio labels when the user points to a <em style="mso-bidi-font-style: normal;">hotspot</em> (a location of interest on an object) with a handheld stylus viewed by the smartphone camera. The CamIO app allows a user to create a new hotspot location by pointing at the location with a second stylus and recording a personalized audio label for the hotspot. In contrast with other audio labeling approaches that require the object of interest to be constructed of special materials, 3D printed, or equipped with special sensors, CamIO works with virtually any rigid object and requires only a smartphone, a paper barcode pattern mounted to the object of interest, and two inexpensive styluses. Moreover, our approach allows a visually impaired user to create audio labels independently. We describe a co-design performed with six blind participants exploring how they label objects in their daily lives and a study with the participants demonstrating the feasibility of CamIO for providing accessible audio labeling.},
	author = {James Coughlan and Huiying Shen and Brandon Biggs}
}
@InProceedings{coughlanEvaluatingAuthorUser2017,
  title = {Evaluating {{Author}} and {{User Experience}} for an {{Audio}}-{{Haptic System}} for {{Annotation}} of {{Physical Models}}},
  booktitle = {Proceedings of the 19th {{International ACM SIGACCESS Conference}} on {{Computers}} and {{Accessibility}}},
  author = {James M. Coughlan and Joshua Miele},
  year = {2017},
  month = {oct},
  pages = {369--370},
  publisher = {{ACM}},
  address = {{Baltimore Maryland USA}},
  doi = {10.1145/3132525.3134811},
  isbn = {978-1-4503-4926-0},
  language = {en},
}
@InProceedings{shenCamIO3DComputer2013,
  title = {{{CamIO}}: A {{3D}} Computer Vision System Enabling Audio/Haptic Interaction with Physical Objects by Blind Users},
  shorttitle = {{{CamIO}}},
  booktitle = {Proceedings of the 15th {{International ACM SIGACCESS Conference}} on {{Computers}} and {{Accessibility}} - {{ASSETS}} '13},
  author = {Huiying Shen and Owen Edwards and Joshua Miele and James M. Coughlan},
  year = {2013},
  pages = {1--2},
  publisher = {{ACM Press}},
  address = {{Bellevue, Washington}},
  doi = {10.1145/2513383.2513423},
  isbn = {978-1-4503-2405-2},
  language = {en},
}
@InProceedings{fuscoTactileGraphicsHelper2015,
  title = {The {{Tactile Graphics Helper}}: {{Providing Audio Clarification}} for {{Tactile Graphics Using Machine Vision}}},
  shorttitle = {The {{Tactile Graphics Helper}}},
  booktitle = {Proceedings of the 17th {{International ACM SIGACCESS Conference}} on {{Computers}} \& {{Accessibility}} - {{ASSETS}} '15},
  author = {Giovanni Fusco and Valerie S. Morash},
  year = {2015},
  pages = {97--106},
  publisher = {{ACM Press}},
  address = {{Lisbon, Portugal}},
  doi = {10.1145/2700648.2809868},
  isbn = {978-1-4503-3400-6},
  language = {en},
}
@InCollection{thevinAugmentedRealityPeople2018,
  title = {Augmented {{Reality}} for {{People}} with {{Visual Impairments}}: {{Designing}} and {{Creating Audio}}-{{Tactile Content}} from {{Existing Objects}}},
  shorttitle = {Augmented {{Reality}} for {{People}} with {{Visual Impairments}}},
  booktitle = {Computers {{Helping People}} with {{Special Needs}}},
  author = {Lauren Thevin and Anke M. Brock},
  editor = {Klaus Miesenberger and Georgios Kouroupetroglou},
  year = {2018},
  volume = {10897},
  pages = {193--200},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-94274-2},
  isbn = {978-3-319-94273-5 978-3-319-94274-2},
}
@InProceedings{shiMarkitTalkitLowBarrier2017,
  title = {Markit and {{Talkit}}: {{A Low}}-{{Barrier Toolkit}} to {{Augment 3D Printed Models}} with {{Audio Annotations}}},
  shorttitle = {Markit and {{Talkit}}},
  booktitle = {Proceedings of the 30th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Lei Shi and Yuhang Zhao and Shiri Azenkot},
  year = {2017},
  month = {oct},
  pages = {493--506},
  publisher = {{ACM}},
  address = {{Quebec City QC Canada}},
  doi = {10.1145/3126594.3126650},
  isbn = {978-1-4503-4981-9},
  language = {en},
}
@Misc{kendrickPenFriendTouchMemo2011,
  title = {{{PenFriend}} and {{Touch Memo}}: {{A Comparison}} of {{Labeling Tools}} | {{AccessWorld}} | {{American Foundation}} for the {{Blind}}},
  author = {Deborah Kendrick},
  year = {2011},
  howpublished = {https://www.afb.org/aw/12/9/15900},
  journal = {American Foundation for the Blind},
}
@Misc{TalkingTactileTablet,
  title = {Talking {{Tactile Tablet}} 2 ({{TTT}}) | {{Touch Graphics Inc}}},
  journal = {Touch Graphics},
  language = {en-US},
}
@InProceedings{mieleTalkingTactileApps2010,
  title = {Talking {{Tactile Apps}} for the {{Pulse Pen}}: {{STEM Binder}}},
  booktitle = {25th {{Annual Int}}'l {{Technology}} \& {{Persons}} with {{Disabilities Conference}} ({{CSUN}})},
  author = {Joshua Miele},
  year = {2010},
}
@incollection{miesenberger_augmented_2018,
	address = {Cham},
	title = {An {Augmented} {Reality} {Audio} {Device} {Helping} {Blind} {People} {Navigation}},
	volume = {10897},
	url = {http://link.springer.com/10.1007/978-3-319-94274-2_5},
	urldate = {2018-10-21},
	booktitle = {Computers {Helping} {People} with {Special} {Needs}},
	publisher = {Springer International Publishing},
	author = {Ferrand, Sylvain and Alouges, Francois and Aussal, Matthieu},
	editor = {Miesenberger, Klaus and Kouroupetroglou, Georgios},
	year = {2018},
	pages = {28--35}
}